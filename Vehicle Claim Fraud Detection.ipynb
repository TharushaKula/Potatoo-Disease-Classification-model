{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2132e612",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing\n",
    "\n",
    "### 1.1 Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bec92b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/tharushakulasinghe/.cache/kagglehub/datasets/shivamb/vehicle-claim-fraud-detection/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"shivamb/vehicle-claim-fraud-detection\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d173ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory contents:\n",
      "  - fraud_oracle.csv\n",
      "\n",
      "Found 1 CSV file(s):\n",
      "  - fraud_oracle.csv\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset structure\n",
    "dataset_path = Path(path)\n",
    "print(\"Dataset directory contents:\")\n",
    "for item in dataset_path.iterdir():\n",
    "    print(f\"  - {item.name}\")\n",
    "\n",
    "# List all CSV files\n",
    "csv_files = list(dataset_path.glob(\"*.csv\"))\n",
    "print(f\"\\nFound {len(csv_files)} CSV file(s):\")\n",
    "for csv_file in csv_files:\n",
    "    print(f\"  - {csv_file.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d16016ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: fraud_oracle.csv\n",
      "Dataset shape: (15420, 33)\n",
      "\n",
      "First few rows:\n",
      "  Month  WeekOfMonth  DayOfWeek    Make AccidentArea DayOfWeekClaimed  \\\n",
      "0   Dec            5  Wednesday   Honda        Urban          Tuesday   \n",
      "1   Jan            3  Wednesday   Honda        Urban           Monday   \n",
      "2   Oct            5     Friday   Honda        Urban         Thursday   \n",
      "3   Jun            2   Saturday  Toyota        Rural           Friday   \n",
      "4   Jan            5     Monday   Honda        Urban          Tuesday   \n",
      "\n",
      "  MonthClaimed  WeekOfMonthClaimed     Sex MaritalStatus  ...  AgeOfVehicle  \\\n",
      "0          Jan                   1  Female        Single  ...       3 years   \n",
      "1          Jan                   4    Male        Single  ...       6 years   \n",
      "2          Nov                   2    Male       Married  ...       7 years   \n",
      "3          Jul                   1    Male       Married  ...   more than 7   \n",
      "4          Feb                   2  Female        Single  ...       5 years   \n",
      "\n",
      "  AgeOfPolicyHolder PoliceReportFiled WitnessPresent AgentType  \\\n",
      "0          26 to 30                No             No  External   \n",
      "1          31 to 35               Yes             No  External   \n",
      "2          41 to 50                No             No  External   \n",
      "3          51 to 65               Yes             No  External   \n",
      "4          31 to 35                No             No  External   \n",
      "\n",
      "   NumberOfSuppliments  AddressChange_Claim  NumberOfCars  Year  BasePolicy  \n",
      "0                 none               1 year        3 to 4  1994   Liability  \n",
      "1                 none            no change     1 vehicle  1994   Collision  \n",
      "2                 none            no change     1 vehicle  1994   Collision  \n",
      "3          more than 5            no change     1 vehicle  1994   Liability  \n",
      "4                 none            no change     1 vehicle  1994   Collision  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# Assuming the main file is the first CSV or has a common name\n",
    "if csv_files:\n",
    "    # Try common names first\n",
    "    possible_names = ['train.csv', 'data.csv', 'vehicle_claim_fraud.csv', 'fraud_detection.csv']\n",
    "    data_file = None\n",
    "    \n",
    "    for name in possible_names:\n",
    "        potential_file = dataset_path / name\n",
    "        if potential_file.exists():\n",
    "            data_file = potential_file\n",
    "            break\n",
    "    \n",
    "    # If not found, use the first CSV file\n",
    "    if data_file is None:\n",
    "        data_file = csv_files[0]\n",
    "    \n",
    "    print(f\"Loading: {data_file.name}\")\n",
    "    df = pd.read_csv(data_file)\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"No CSV files found in the dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30115477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "==================================================\n",
      "Shape: (15420, 33)\n",
      "\n",
      "Column names:\n",
      "['Month', 'WeekOfMonth', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed', 'MonthClaimed', 'WeekOfMonthClaimed', 'Sex', 'MaritalStatus', 'Age', 'Fault', 'PolicyType', 'VehicleCategory', 'VehiclePrice', 'FraudFound_P', 'PolicyNumber', 'RepNumber', 'Deductible', 'DriverRating', 'Days_Policy_Accident', 'Days_Policy_Claim', 'PastNumberOfClaims', 'AgeOfVehicle', 'AgeOfPolicyHolder', 'PoliceReportFiled', 'WitnessPresent', 'AgentType', 'NumberOfSuppliments', 'AddressChange_Claim', 'NumberOfCars', 'Year', 'BasePolicy']\n",
      "\n",
      "Data types:\n",
      "Month                   object\n",
      "WeekOfMonth              int64\n",
      "DayOfWeek               object\n",
      "Make                    object\n",
      "AccidentArea            object\n",
      "DayOfWeekClaimed        object\n",
      "MonthClaimed            object\n",
      "WeekOfMonthClaimed       int64\n",
      "Sex                     object\n",
      "MaritalStatus           object\n",
      "Age                      int64\n",
      "Fault                   object\n",
      "PolicyType              object\n",
      "VehicleCategory         object\n",
      "VehiclePrice            object\n",
      "FraudFound_P             int64\n",
      "PolicyNumber             int64\n",
      "RepNumber                int64\n",
      "Deductible               int64\n",
      "DriverRating             int64\n",
      "Days_Policy_Accident    object\n",
      "Days_Policy_Claim       object\n",
      "PastNumberOfClaims      object\n",
      "AgeOfVehicle            object\n",
      "AgeOfPolicyHolder       object\n",
      "PoliceReportFiled       object\n",
      "WitnessPresent          object\n",
      "AgentType               object\n",
      "NumberOfSuppliments     object\n",
      "AddressChange_Claim     object\n",
      "NumberOfCars            object\n",
      "Year                     int64\n",
      "BasePolicy              object\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "Month                   0\n",
      "WeekOfMonth             0\n",
      "DayOfWeek               0\n",
      "Make                    0\n",
      "AccidentArea            0\n",
      "DayOfWeekClaimed        0\n",
      "MonthClaimed            0\n",
      "WeekOfMonthClaimed      0\n",
      "Sex                     0\n",
      "MaritalStatus           0\n",
      "Age                     0\n",
      "Fault                   0\n",
      "PolicyType              0\n",
      "VehicleCategory         0\n",
      "VehiclePrice            0\n",
      "FraudFound_P            0\n",
      "PolicyNumber            0\n",
      "RepNumber               0\n",
      "Deductible              0\n",
      "DriverRating            0\n",
      "Days_Policy_Accident    0\n",
      "Days_Policy_Claim       0\n",
      "PastNumberOfClaims      0\n",
      "AgeOfVehicle            0\n",
      "AgeOfPolicyHolder       0\n",
      "PoliceReportFiled       0\n",
      "WitnessPresent          0\n",
      "AgentType               0\n",
      "NumberOfSuppliments     0\n",
      "AddressChange_Claim     0\n",
      "NumberOfCars            0\n",
      "Year                    0\n",
      "BasePolicy              0\n",
      "dtype: int64\n",
      "\n",
      "Basic statistics:\n",
      "        WeekOfMonth  WeekOfMonthClaimed           Age  FraudFound_P  \\\n",
      "count  15420.000000        15420.000000  15420.000000  15420.000000   \n",
      "mean       2.788586            2.693969     39.855707      0.059857   \n",
      "std        1.287585            1.259115     13.492377      0.237230   \n",
      "min        1.000000            1.000000      0.000000      0.000000   \n",
      "25%        2.000000            2.000000     31.000000      0.000000   \n",
      "50%        3.000000            3.000000     38.000000      0.000000   \n",
      "75%        4.000000            4.000000     48.000000      0.000000   \n",
      "max        5.000000            5.000000     80.000000      1.000000   \n",
      "\n",
      "       PolicyNumber     RepNumber    Deductible  DriverRating          Year  \n",
      "count  15420.000000  15420.000000  15420.000000  15420.000000  15420.000000  \n",
      "mean    7710.500000      8.483268    407.704280      2.487808   1994.866472  \n",
      "std     4451.514911      4.599948     43.950998      1.119453      0.803313  \n",
      "min        1.000000      1.000000    300.000000      1.000000   1994.000000  \n",
      "25%     3855.750000      5.000000    400.000000      1.000000   1994.000000  \n",
      "50%     7710.500000      8.000000    400.000000      2.000000   1995.000000  \n",
      "75%    11565.250000     12.000000    400.000000      3.000000   1996.000000  \n",
      "max    15420.000000     16.000000    700.000000      4.000000   1996.000000  \n"
     ]
    }
   ],
   "source": [
    "# Dataset Information\n",
    "print(\"Dataset Info:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf7875",
   "metadata": {},
   "source": [
    "### 1.2 Data Cleaning and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38b829c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_count = df_processed.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "if duplicate_count > 0:\n",
    "    df_processed = df_processed.drop_duplicates()\n",
    "    print(f\"Removed {duplicate_count} duplicate rows\")\n",
    "    print(f\"New shape: {df_processed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bb1fa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Missing values after handling:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "print(\"Missing values before handling:\")\n",
    "missing_before = df_processed.isnull().sum()\n",
    "print(missing_before[missing_before > 0])\n",
    "\n",
    "# Strategy for handling missing values\n",
    "# For numerical columns: fill with median\n",
    "# For categorical columns: fill with mode or 'Unknown'\n",
    "for col in df_processed.columns:\n",
    "    if df_processed[col].isnull().sum() > 0:\n",
    "        if df_processed[col].dtype in ['int64', 'float64']:\n",
    "            # Fill numerical columns with median\n",
    "            median_val = df_processed[col].median()\n",
    "            df_processed[col].fillna(median_val, inplace=True)\n",
    "            print(f\"Filled {col} (numerical) with median: {median_val}\")\n",
    "        else:\n",
    "            # Fill categorical columns with mode\n",
    "            mode_val = df_processed[col].mode()[0] if not df_processed[col].mode().empty else 'Unknown'\n",
    "            df_processed[col].fillna(mode_val, inplace=True)\n",
    "            print(f\"Filled {col} (categorical) with mode: {mode_val}\")\n",
    "\n",
    "print(\"\\nMissing values after handling:\")\n",
    "missing_after = df_processed.isnull().sum()\n",
    "print(missing_after[missing_after > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61591c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential target variables: ['FraudFound_P']\n",
      "\n",
      "Target variable: FraudFound_P\n",
      "Value counts:\n",
      "FraudFound_P\n",
      "0    14497\n",
      "1      923\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts (percentage):\n",
      "FraudFound_P\n",
      "0    94.014267\n",
      "1     5.985733\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Identify target variable (assuming it's named 'fraud' or 'is_fraud' or similar)\n",
    "target_candidates = [col for col in df_processed.columns if 'fraud' in col.lower() or 'target' in col.lower() or 'label' in col.lower()]\n",
    "print(\"Potential target variables:\", target_candidates)\n",
    "\n",
    "# If no obvious target found, check the last column or columns with binary values\n",
    "if not target_candidates:\n",
    "    # Check last column\n",
    "    last_col = df_processed.columns[-1]\n",
    "    if df_processed[last_col].nunique() <= 2:\n",
    "        target_candidates = [last_col]\n",
    "        print(f\"Assuming target variable is: {last_col}\")\n",
    "\n",
    "# Display target variable distribution\n",
    "if target_candidates:\n",
    "    target_col = target_candidates[0]\n",
    "    print(f\"\\nTarget variable: {target_col}\")\n",
    "    print(f\"Value counts:\")\n",
    "    print(df_processed[target_col].value_counts())\n",
    "    print(f\"\\nValue counts (percentage):\")\n",
    "    print(df_processed[target_col].value_counts(normalize=True) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "166e4520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (15420, 32)\n",
      "Target shape: (15420,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "if target_candidates:\n",
    "    target_col = target_candidates[0]\n",
    "    y = df_processed[target_col]\n",
    "    X = df_processed.drop(columns=[target_col])\n",
    "    \n",
    "    print(f\"Features shape: {X.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "else:\n",
    "    print(\"Warning: Could not identify target variable. Please specify manually.\")\n",
    "    X = df_processed\n",
    "    y = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0643d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns (24): ['Month', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed', 'MonthClaimed', 'Sex', 'MaritalStatus', 'Fault', 'PolicyType', 'VehicleCategory', 'VehiclePrice', 'Days_Policy_Accident', 'Days_Policy_Claim', 'PastNumberOfClaims', 'AgeOfVehicle', 'AgeOfPolicyHolder', 'PoliceReportFiled', 'WitnessPresent', 'AgentType', 'NumberOfSuppliments', 'AddressChange_Claim', 'NumberOfCars', 'BasePolicy']\n",
      "\n",
      "Numerical columns (8): ['WeekOfMonth', 'WeekOfMonthClaimed', 'Age', 'PolicyNumber', 'RepNumber', 'Deductible', 'DriverRating', 'Year']\n",
      "\n",
      "Categorical column unique value counts:\n",
      "\n",
      "Month:\n",
      "  Unique values: 12\n",
      "  Values: ['Dec' 'Jan' 'Oct' 'Jun' 'Feb' 'Nov' 'Apr' 'Mar' 'Aug' 'Jul' 'May' 'Sep']\n",
      "\n",
      "DayOfWeek:\n",
      "  Unique values: 7\n",
      "  Values: ['Wednesday' 'Friday' 'Saturday' 'Monday' 'Tuesday' 'Sunday' 'Thursday']\n",
      "\n",
      "Make:\n",
      "  Unique values: 19\n",
      "  Values: ['Honda' 'Toyota' 'Ford' 'Mazda' 'Chevrolet' 'Pontiac' 'Accura' 'Dodge'\n",
      " 'Mercury' 'Jaguar' 'Nisson' 'VW' 'Saab' 'Saturn' 'Porche' 'BMW' 'Mecedes'\n",
      " 'Ferrari' 'Lexus']\n",
      "\n",
      "AccidentArea:\n",
      "  Unique values: 2\n",
      "  Values: ['Urban' 'Rural']\n",
      "\n",
      "DayOfWeekClaimed:\n",
      "  Unique values: 8\n",
      "  Values: ['Tuesday' 'Monday' 'Thursday' 'Friday' 'Wednesday' 'Saturday' 'Sunday'\n",
      " '0']\n",
      "\n",
      "MonthClaimed:\n",
      "  Unique values: 13\n",
      "  Values: ['Jan' 'Nov' 'Jul' 'Feb' 'Mar' 'Dec' 'Apr' 'Aug' 'May' 'Jun' 'Sep' 'Oct'\n",
      " '0']\n",
      "\n",
      "Sex:\n",
      "  Unique values: 2\n",
      "  Values: ['Female' 'Male']\n",
      "\n",
      "MaritalStatus:\n",
      "  Unique values: 4\n",
      "  Values: ['Single' 'Married' 'Widow' 'Divorced']\n",
      "\n",
      "Fault:\n",
      "  Unique values: 2\n",
      "  Values: ['Policy Holder' 'Third Party']\n",
      "\n",
      "PolicyType:\n",
      "  Unique values: 9\n",
      "  Values: ['Sport - Liability' 'Sport - Collision' 'Sedan - Liability'\n",
      " 'Utility - All Perils' 'Sedan - All Perils' 'Sedan - Collision'\n",
      " 'Utility - Collision' 'Utility - Liability' 'Sport - All Perils']\n",
      "\n",
      "VehicleCategory:\n",
      "  Unique values: 3\n",
      "  Values: ['Sport' 'Utility' 'Sedan']\n",
      "\n",
      "VehiclePrice:\n",
      "  Unique values: 6\n",
      "  Values: ['more than 69000' '20000 to 29000' '30000 to 39000' 'less than 20000'\n",
      " '40000 to 59000' '60000 to 69000']\n",
      "\n",
      "Days_Policy_Accident:\n",
      "  Unique values: 5\n",
      "  Values: ['more than 30' '15 to 30' 'none' '1 to 7' '8 to 15']\n",
      "\n",
      "Days_Policy_Claim:\n",
      "  Unique values: 4\n",
      "  Values: ['more than 30' '15 to 30' '8 to 15' 'none']\n",
      "\n",
      "PastNumberOfClaims:\n",
      "  Unique values: 4\n",
      "  Values: ['none' '1' '2 to 4' 'more than 4']\n",
      "\n",
      "AgeOfVehicle:\n",
      "  Unique values: 8\n",
      "  Values: ['3 years' '6 years' '7 years' 'more than 7' '5 years' 'new' '4 years'\n",
      " '2 years']\n",
      "\n",
      "AgeOfPolicyHolder:\n",
      "  Unique values: 9\n",
      "  Values: ['26 to 30' '31 to 35' '41 to 50' '51 to 65' '21 to 25' '36 to 40'\n",
      " '16 to 17' 'over 65' '18 to 20']\n",
      "\n",
      "PoliceReportFiled:\n",
      "  Unique values: 2\n",
      "  Values: ['No' 'Yes']\n",
      "\n",
      "WitnessPresent:\n",
      "  Unique values: 2\n",
      "  Values: ['No' 'Yes']\n",
      "\n",
      "AgentType:\n",
      "  Unique values: 2\n",
      "  Values: ['External' 'Internal']\n",
      "\n",
      "NumberOfSuppliments:\n",
      "  Unique values: 4\n",
      "  Values: ['none' 'more than 5' '3 to 5' '1 to 2']\n",
      "\n",
      "AddressChange_Claim:\n",
      "  Unique values: 5\n",
      "  Values: ['1 year' 'no change' '4 to 8 years' '2 to 3 years' 'under 6 months']\n",
      "\n",
      "NumberOfCars:\n",
      "  Unique values: 5\n",
      "  Values: ['3 to 4' '1 vehicle' '2 vehicles' '5 to 8' 'more than 8']\n",
      "\n",
      "BasePolicy:\n",
      "  Unique values: 3\n",
      "  Values: ['Liability' 'Collision' 'All Perils']\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "print(f\"\\nNumerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "\n",
    "# Display unique values in categorical columns\n",
    "if categorical_cols:\n",
    "    print(\"\\nCategorical column unique value counts:\")\n",
    "    for col in categorical_cols:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Unique values: {X[col].nunique()}\")\n",
    "        if X[col].nunique() <= 20:\n",
    "            print(f\"  Values: {X[col].unique()}\")\n",
    "        else:\n",
    "            print(f\"  First 10 values: {X[col].unique()[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f14af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Month: 12 unique values\n",
      "Encoded DayOfWeek: 7 unique values\n",
      "Encoded Make: 19 unique values\n",
      "Encoded AccidentArea: 2 unique values\n",
      "Encoded DayOfWeekClaimed: 8 unique values\n",
      "Encoded MonthClaimed: 13 unique values\n",
      "Encoded Sex: 2 unique values\n",
      "Encoded MaritalStatus: 4 unique values\n",
      "Encoded Fault: 2 unique values\n",
      "Encoded PolicyType: 9 unique values\n",
      "Encoded VehicleCategory: 3 unique values\n",
      "Encoded VehiclePrice: 6 unique values\n",
      "Encoded Days_Policy_Accident: 5 unique values\n",
      "Encoded Days_Policy_Claim: 4 unique values\n",
      "Encoded PastNumberOfClaims: 4 unique values\n",
      "Encoded AgeOfVehicle: 8 unique values\n",
      "Encoded AgeOfPolicyHolder: 9 unique values\n",
      "Encoded PoliceReportFiled: 2 unique values\n",
      "Encoded WitnessPresent: 2 unique values\n",
      "Encoded AgentType: 2 unique values\n",
      "Encoded NumberOfSuppliments: 4 unique values\n",
      "Encoded AddressChange_Claim: 5 unique values\n",
      "Encoded NumberOfCars: 5 unique values\n",
      "Encoded BasePolicy: 3 unique values\n",
      "\n",
      "Encoded dataset shape: (15420, 32)\n",
      "\n",
      "Encoded dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15420 entries, 0 to 15419\n",
      "Data columns (total 32 columns):\n",
      " #   Column                Non-Null Count  Dtype\n",
      "---  ------                --------------  -----\n",
      " 0   Month                 15420 non-null  int64\n",
      " 1   WeekOfMonth           15420 non-null  int64\n",
      " 2   DayOfWeek             15420 non-null  int64\n",
      " 3   Make                  15420 non-null  int64\n",
      " 4   AccidentArea          15420 non-null  int64\n",
      " 5   DayOfWeekClaimed      15420 non-null  int64\n",
      " 6   MonthClaimed          15420 non-null  int64\n",
      " 7   WeekOfMonthClaimed    15420 non-null  int64\n",
      " 8   Sex                   15420 non-null  int64\n",
      " 9   MaritalStatus         15420 non-null  int64\n",
      " 10  Age                   15420 non-null  int64\n",
      " 11  Fault                 15420 non-null  int64\n",
      " 12  PolicyType            15420 non-null  int64\n",
      " 13  VehicleCategory       15420 non-null  int64\n",
      " 14  VehiclePrice          15420 non-null  int64\n",
      " 15  PolicyNumber          15420 non-null  int64\n",
      " 16  RepNumber             15420 non-null  int64\n",
      " 17  Deductible            15420 non-null  int64\n",
      " 18  DriverRating          15420 non-null  int64\n",
      " 19  Days_Policy_Accident  15420 non-null  int64\n",
      " 20  Days_Policy_Claim     15420 non-null  int64\n",
      " 21  PastNumberOfClaims    15420 non-null  int64\n",
      " 22  AgeOfVehicle          15420 non-null  int64\n",
      " 23  AgeOfPolicyHolder     15420 non-null  int64\n",
      " 24  PoliceReportFiled     15420 non-null  int64\n",
      " 25  WitnessPresent        15420 non-null  int64\n",
      " 26  AgentType             15420 non-null  int64\n",
      " 27  NumberOfSuppliments   15420 non-null  int64\n",
      " 28  AddressChange_Claim   15420 non-null  int64\n",
      " 29  NumberOfCars          15420 non-null  int64\n",
      " 30  Year                  15420 non-null  int64\n",
      " 31  BasePolicy            15420 non-null  int64\n",
      "dtypes: int64(32)\n",
      "memory usage: 3.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode categorical variables\n",
    "X_encoded = X.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "    print(f\"Encoded {col}: {len(le.classes_)} unique values\")\n",
    "\n",
    "print(f\"\\nEncoded dataset shape: {X_encoded.shape}\")\n",
    "print(f\"\\nEncoded dataset info:\")\n",
    "print(X_encoded.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1654a241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable is already numerical\n",
      "Target distribution: [14497   923]\n"
     ]
    }
   ],
   "source": [
    "# Encode target variable if it's categorical\n",
    "if y is not None:\n",
    "    if y.dtype == 'object':\n",
    "        le_target = LabelEncoder()\n",
    "        y_encoded = le_target.fit_transform(y)\n",
    "        print(f\"Target variable classes: {le_target.classes_}\")\n",
    "        print(f\"Target distribution: {np.bincount(y_encoded)}\")\n",
    "    else:\n",
    "        y_encoded = y.values\n",
    "        print(f\"Target variable is already numerical\")\n",
    "        print(f\"Target distribution: {np.bincount(y_encoded.astype(int))}\")\n",
    "else:\n",
    "    y_encoded = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d982834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: X_train (12336, 32), y_train (12336,)\n",
      "Test set shape: X_test (3084, 32), y_test (3084,)\n",
      "\n",
      "Training set target distribution:\n",
      "  Class 0: 11598 (94.02%)\n",
      "  Class 1: 738 (5.98%)\n",
      "\n",
      "Test set target distribution:\n",
      "  Class 0: 2899 (94.00%)\n",
      "  Class 1: 185 (6.00%)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "if y_encoded is not None:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_encoded, y_encoded, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set shape: X_train {X_train.shape}, y_train {y_train.shape}\")\n",
    "    print(f\"Test set shape: X_test {X_test.shape}, y_test {y_test.shape}\")\n",
    "    print(f\"\\nTraining set target distribution:\")\n",
    "    print(f\"  Class 0: {np.sum(y_train == 0)} ({np.sum(y_train == 0)/len(y_train)*100:.2f}%)\")\n",
    "    print(f\"  Class 1: {np.sum(y_train == 1)} ({np.sum(y_train == 1)/len(y_train)*100:.2f}%)\")\n",
    "    print(f\"\\nTest set target distribution:\")\n",
    "    print(f\"  Class 0: {np.sum(y_test == 0)} ({np.sum(y_test == 0)/len(y_test)*100:.2f}%)\")\n",
    "    print(f\"  Class 1: {np.sum(y_test == 1)} ({np.sum(y_test == 1)/len(y_test)*100:.2f}%)\")\n",
    "else:\n",
    "    print(\"No target variable available for splitting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2b503ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scaling completed using StandardScaler\n",
      "Scaled training set shape: (12336, 32)\n",
      "Scaled test set shape: (3084, 32)\n",
      "\n",
      "Scaled training set statistics:\n",
      "              Month   WeekOfMonth     DayOfWeek          Make  AccidentArea  \\\n",
      "count  1.233600e+04  1.233600e+04  1.233600e+04  1.233600e+04  1.233600e+04   \n",
      "mean   1.002225e-16 -6.796696e-17  1.382379e-17  8.063877e-17 -9.907049e-17   \n",
      "std    1.000041e+00  1.000041e+00  1.000041e+00  1.000041e+00  1.000041e+00   \n",
      "min   -1.617038e+00 -1.395817e+00 -1.417715e+00 -1.915634e+00 -2.898696e+00   \n",
      "25%   -7.381391e-01 -6.158740e-01 -9.321408e-01 -7.807525e-01  3.449827e-01   \n",
      "50%    1.407596e-01  1.640687e-01  3.900813e-02 -2.133116e-01  3.449827e-01   \n",
      "75%    7.266921e-01  9.440113e-01  1.010157e+00  5.432762e-01  3.449827e-01   \n",
      "max    1.605591e+00  1.723954e+00  1.495732e+00  1.489011e+00  3.449827e-01   \n",
      "\n",
      "       DayOfWeekClaimed  MonthClaimed  WeekOfMonthClaimed           Sex  \\\n",
      "count      1.233600e+04  1.233600e+04        1.233600e+04  1.233600e+04   \n",
      "mean      -1.618535e-16  8.294273e-17        4.895925e-17 -4.953524e-17   \n",
      "std        1.000041e+00  1.000041e+00        1.000041e+00  1.000041e+00   \n",
      "min       -1.841595e+00 -1.936371e+00       -1.356363e+00 -2.329882e+00   \n",
      "25%       -9.620615e-01 -7.629051e-01       -5.591791e-01  4.292064e-01   \n",
      "50%        3.572393e-01  1.171944e-01        2.380049e-01  4.292064e-01   \n",
      "75%        7.970063e-01  7.039274e-01        1.035189e+00  4.292064e-01   \n",
      "max        1.236773e+00  1.584027e+00        1.832373e+00  4.292064e-01   \n",
      "\n",
      "       MaritalStatus  ...  AgeOfVehicle  AgeOfPolicyHolder  PoliceReportFiled  \\\n",
      "count   1.233600e+04  ...  1.233600e+04       1.233600e+04       1.233600e+04   \n",
      "mean    2.332764e-17  ... -4.435132e-17       2.303965e-16      -4.953524e-17   \n",
      "std     1.000041e+00  ...  1.000041e+00       1.000041e+00       1.000041e+00   \n",
      "min    -2.739522e+00  ... -4.230869e+00      -3.514100e+00      -1.663053e-01   \n",
      "25%    -6.413818e-01  ... -7.031311e-01      -6.424349e-01      -1.663053e-01   \n",
      "50%    -6.413818e-01  ...  1.788033e-01       7.548130e-02      -1.663053e-01   \n",
      "75%     1.456758e+00  ...  1.060738e+00       7.933976e-01      -1.663053e-01   \n",
      "max     3.554898e+00  ...  1.942672e+00       2.229230e+00       6.013038e+00   \n",
      "\n",
      "       WitnessPresent     AgentType  NumberOfSuppliments  AddressChange_Claim  \\\n",
      "count    1.233600e+04  1.233600e+04         1.233600e+04         1.233600e+04   \n",
      "mean     1.324780e-17  1.439978e-18         8.639868e-18        -3.765542e-16   \n",
      "std      1.000041e+00  1.000041e+00         1.000041e+00         1.000041e+00   \n",
      "min     -7.554358e-02 -1.296728e-01        -1.797048e+00        -6.368118e+00   \n",
      "25%     -7.554358e-02 -1.296728e-01        -8.963700e-01         2.494461e-01   \n",
      "50%     -7.554358e-02 -1.296728e-01         4.307716e-03         2.494461e-01   \n",
      "75%     -7.554358e-02 -1.296728e-01         9.049855e-01         2.494461e-01   \n",
      "max      1.323739e+01  7.711718e+00         9.049855e-01         2.455301e+00   \n",
      "\n",
      "       NumberOfCars          Year    BasePolicy  \n",
      "count  1.233600e+04  1.233600e+04  1.233600e+04  \n",
      "mean   4.319934e-17 -7.860120e-14 -1.290220e-16  \n",
      "std    1.000041e+00  1.000041e+00  1.000041e+00  \n",
      "min   -2.631086e-01 -1.072874e+00 -1.331685e+00  \n",
      "25%   -2.631086e-01 -1.072874e+00 -1.331685e+00  \n",
      "50%   -2.631086e-01  1.731225e-01 -5.117474e-02  \n",
      "75%   -2.631086e-01  1.419119e+00  1.229336e+00  \n",
      "max    9.935500e+00  1.419119e+00  1.229336e+00  \n",
      "\n",
      "[8 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling (StandardScaler for numerical features)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"Feature scaling completed using StandardScaler\")\n",
    "print(f\"Scaled training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled test set shape: {X_test_scaled.shape}\")\n",
    "print(f\"\\nScaled training set statistics:\")\n",
    "print(X_train_scaled.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "889a6d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREPROCESSING SUMMARY\n",
      "============================================================\n",
      "Original dataset shape: (15420, 33)\n",
      "After removing duplicates: (15420, 33)\n",
      "Number of features: 32\n",
      "  - Categorical features: 24\n",
      "  - Numerical features: 8\n",
      "\n",
      "Data split:\n",
      "  - Training set: 12336 samples\n",
      "  - Test set: 3084 samples\n",
      "  - Test size: 20%\n",
      "\n",
      "Preprocessing steps completed:\n",
      "  ✓ Removed duplicate rows\n",
      "  ✓ Handled missing values\n",
      "  ✓ Encoded categorical variables\n",
      "  ✓ Scaled features using StandardScaler\n",
      "  ✓ Split data into training and test sets\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary of preprocessing steps\n",
    "print(\"=\" * 60)\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"After removing duplicates: {df_processed.shape}\")\n",
    "print(f\"Number of features: {X_encoded.shape[1]}\")\n",
    "print(f\"  - Categorical features: {len(categorical_cols)}\")\n",
    "print(f\"  - Numerical features: {len(numerical_cols)}\")\n",
    "print(f\"\\nData split:\")\n",
    "if y_encoded is not None:\n",
    "    print(f\"  - Training set: {X_train_scaled.shape[0]} samples\")\n",
    "    print(f\"  - Test set: {X_test_scaled.shape[0]} samples\")\n",
    "    print(f\"  - Test size: 20%\")\n",
    "print(f\"\\nPreprocessing steps completed:\")\n",
    "print(\"  ✓ Removed duplicate rows\")\n",
    "print(\"  ✓ Handled missing values\")\n",
    "print(\"  ✓ Encoded categorical variables\")\n",
    "print(\"  ✓ Scaled features using StandardScaler\")\n",
    "if y_encoded is not None:\n",
    "    print(\"  ✓ Split data into training and test sets\")\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
